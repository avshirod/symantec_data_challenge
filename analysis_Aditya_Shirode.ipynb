{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symantec - Data Analysis Exercise\n",
    "##### Submiited by: Aditya Shirode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading about the data at hand, which is in JSON Lines format, the initial thoughts were -  \n",
    "- Do I need to load the data into a database?\n",
    "- If yes, what would be the best way to do that?\n",
    "- If not, then do I need to store it in some data structure locally, or can I just analyze on the fly?\n",
    "\n",
    "Both of the options mentioned above are possible, but to make the experiment flexible and extensible, it was pertinent that we store the data in some database.  \n",
    "\n",
    "Since the data is in a flexible format (JSON), we need a database which is not constrained by a rigid, pre-defined structure, hence NoSQL.  \n",
    "Among NoSQL databases, MongoDB - a document oriented database, which can easily work with JSON format, seems perfect fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is [MongoDB](https://www.mongodb.com/what-is-mongodb):  \n",
    "A NoSQL, document database  \n",
    "Free and open source  \n",
    "\n",
    "What we gain from MongoDB:\n",
    "- Native data representation is JSON\n",
    "- Can do simple real time aggregation, which covers the basic queries we need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use PyMongo to load the data and answer our queries  \n",
    "\n",
    "###### [PyMongo](http://api.mongodb.com/python/current/index.htm):  \n",
    "- PyMongo is a driver for MongoDB in Python  \n",
    "- It connects Python application to *'mongod'* (MongoDB Daemon) using BSON (Binary JSON)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How to setup MongoDB:  \n",
    "- Download the MongoDB installer for the community release [here](https://www.mongodb.com/download-center?jmp=nav#community)\n",
    "- Select the version based on the operating system you are running this application on\n",
    "- Run the installer after download is completed\n",
    "- Go through the installation with default settings\n",
    "\n",
    "\n",
    "- Navigate to the MongoDB installation on your local machine (For Windows, the default is 'C:\\Program Files\\MongoDB\\Server\\3.4')\n",
    "- Create two new folders inside the above folder: */data* and */log*\n",
    "- Navigate to the */data/* folder and create another folder */db*\n",
    "- Now, the directory structure inside the MongoDB folder should be:\n",
    "    - */bin*\n",
    "    - */data/db*\n",
    "    - */log*\n",
    "    - and some other files\n",
    "\n",
    "- Now open a terminal and navigate to the */bin* folder mentioned above\n",
    "- Run the following command:  \n",
    "> ```mongod --directoryperdb --dbpath 'C:\\\\Program Files\\\\MongoDB\\\\Server\\\\3.4\\\\data\\\\db'   \n",
    "--logpath 'C:\\\\Program Files\\\\MongoDB\\\\Server\\\\3.4\\\\log\\\\mongo.log'  \n",
    "--logappend --rest --install```\n",
    "\n",
    "- This command will start the MongoDB daemon with settings as:\n",
    "    - **--directoryperdb**: Uses a separate directory to store data for each database (separation per database)\n",
    "    - **--dbpath [path]**: The directory where the mongod instance stores its data (In our case ..\\data\\db)\n",
    "    - **--logpath [path]**: Sends all diagnostic logging information to a log file (We store our log in ..\\log\\Mongo.log)\n",
    "    - **--logappend**: Append new entries to the end of the existing log file\n",
    "    - **--rest**: Enables the simple REST API, to use MongoDB as a service\n",
    "    - **--install**: Installs the service\n",
    "    \n",
    "- Start the service by running following command:  \n",
    "    > ```net start MongoDB```\n",
    "    \n",
    "Note: All of this is explained in detail on [MongoDB Windows Installation](https://docs.mongodb.com/manual/tutorial/install-mongodb-on-windows/) and [MongoDB Documentation](https://docs.mongodb.com/manual/reference/program/mongod/)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Installing PyMongo:\n",
    "Run following command to [install](http://api.mongodb.com/python/current/installation.html) PyMongo:  \n",
    "> ```pip install pymongo```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuts:  \n",
    "https://www.youtube.com/watch?v=GSL8JpyAjsE  \n",
    "https://www.youtube.com/watch?v=pWbMrx5rVBE  \n",
    "http://api.mongodb.com/python/current/tutorial.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a running instance of MongoDB, let's load our data in it using *PyMongo*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup connection to client\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a Database\n",
    "db = client.symantec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a collection - group of documents\n",
    "collection = db.people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Directory where our 'JSONL' file is stored\n",
    "DATA_DIR = os.path.join(os.getcwd(), 'data')\n",
    "filename = 'ida_wrangling_exercise_data.2017-02-13.jsonl'\n",
    "\n",
    "# Open the file, parse entry one by one, and load into database\n",
    "with open(os.path.join(DATA_DIR, filename)) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        line = line.strip()\n",
    "        collection.insert_one(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('59c376c1b1531e28986dd31f'),\n",
      " 'address': {'city': 'Hoodburgh',\n",
      "             'state': 'RI',\n",
      "             'street': '86314 David Pass Apt. 211',\n",
      "             'zip': '83973'},\n",
      " 'dob': '1971-06-30',\n",
      " 'email': 'opark@hotmail.com',\n",
      " 'id': '01d68a4c598a45559c06f4df0b3d82cb',\n",
      " 'name': {'firstname': 'Cynthia', 'lastname': 'Dawson', 'middlename': 'Claire'},\n",
      " 'phone': '624-869-4610',\n",
      " 'record_date': '2006-07-08T09:02:13',\n",
      " 'ssn': 'xxx-xx-2412'}\n"
     ]
    }
   ],
   "source": [
    "# Check if the data is loaded by randomly checking one entry\n",
    "from pprint import pprint\n",
    "pprint(collection.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total no of records\n",
    "n = collection.count()\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis\n",
    "\n",
    "Now that we have our data loaded, we can find answers to our questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q1\n",
    "Start by making a list of all of the nested named fields that appear in any record.  \n",
    "Concatenate nested field names using a period '.' to defind named fields for nested records.  \n",
    "Present the list in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['address', 'address.city', 'address.state', 'address.street', 'address.zip', 'dob', 'email', 'id', 'name', 'name.firstname', 'name.lastname', 'name.middlename', 'phone', 'record_date', 'ssn']\n"
     ]
    }
   ],
   "source": [
    "# Maintain a set of keys found\n",
    "keys = set()\n",
    "\n",
    "# A function similar to flattening a list of lists\n",
    "def flatten(record, parent=list()):\n",
    "    ''' Function to flatten a record '''\n",
    "    for key, value in record.items():\n",
    "        if type(value) is dict: # If nested record, recurse with updated parent\n",
    "            flatten(value, parent + [key])\n",
    "        if parent:\n",
    "            keys.add('.'.join(parent + [key]))\n",
    "        else:\n",
    "            keys.add(key)\n",
    "                \n",
    "for record in collection.find():\n",
    "    flatten(record)\n",
    "\n",
    "# Remove the '_id' field generated by MongoDB while inserting the records\n",
    "keys.remove('_id')\n",
    "\n",
    "print(sorted(keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would have been better to keep track of these when inserting records into the database,  \n",
    "because we are iterating over every record again to calculate the desired result.\n",
    "\n",
    "There are complex way to do the same recursion, by utilizing MongoDB functions such as 'MapReduce', 'aggregate'; but given the short amount of time, let's go the straightforward way.  \n",
    "Given more time, it'd be interesting to see which method performs fastest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q2\n",
    "- What percentage of the records contain the field?\n",
    "- What are the five most common values of the field?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating the above query a bit, we can update a counter and find out these answers.  \n",
    "\n",
    "We can utilize the the aggregate function that MongoDB provides, but we'll lose the hierarchy in doing that.  \n",
    "We can write a helper Script function outside, but that would not be completely Pythonic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintain a set of keys found\n",
    "keys_counter = dict()\n",
    "\n",
    "# A function similar to flattening a list of lists\n",
    "def flatten(record, parent=list()):\n",
    "    ''' Function to flatten a record '''\n",
    "    for key, value in record.items():\n",
    "        if type(value) is dict: # If nested record, recurse with updated parent\n",
    "            flatten(value, parent + [key])\n",
    "        \n",
    "        # Instead of adding the key found to a set, we are maintaing a dictionary counter\n",
    "        key = '.'.join(parent + [key])\n",
    "        keys_counter[key] = keys_counter.get(key, 0) + 1\n",
    "                \n",
    "for record in collection.find():\n",
    "    flatten(record)\n",
    "\n",
    "# Remove the '_id' field generated by MongoDB while inserting the records\n",
    "_ = keys_counter.pop('_id')\n",
    "# assert _ == n # The no of '_id' popped out should be equal to the total number of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'address': 136426,\n",
      " 'address.city': 61233,\n",
      " 'address.state': 61233,\n",
      " 'address.street': 61233,\n",
      " 'address.zip': 61233,\n",
      " 'dob': 143874,\n",
      " 'email': 130880,\n",
      " 'id': 150000,\n",
      " 'name': 148062,\n",
      " 'name.firstname': 105004,\n",
      " 'name.lastname': 105004,\n",
      " 'name.middlename': 43669,\n",
      " 'phone': 140261,\n",
      " 'record_date': 150000,\n",
      " 'ssn': 142444}\n"
     ]
    }
   ],
   "source": [
    "pprint(keys_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "address           90.95%\n",
      "address.city      40.82%\n",
      "address.state     40.82%\n",
      "address.street    40.82%\n",
      "address.zip       40.82%\n",
      "dob               95.92%\n",
      "email             87.25%\n",
      "id               100.00%\n",
      "name              98.71%\n",
      "name.firstname    70.00%\n",
      "name.lastname     70.00%\n",
      "name.middlename   29.11%\n",
      "phone             93.51%\n",
      "record_date      100.00%\n",
      "ssn               94.96%\n"
     ]
    }
   ],
   "source": [
    "# OrderedDict to maintain the alphabetical sorted order\n",
    "from collections import OrderedDict\n",
    "keys_counter_ordered = OrderedDict(sorted(keys_counter.items()))\n",
    "\n",
    "# Since we have count corresponding to each key, \n",
    "# And we have n = total no of records,\n",
    "# We can calculate percentage easily\n",
    "for key, val in keys_counter_ordered.items():\n",
    "    print(\"{:16} {:6.2f}%\".format(key, val * 100 / n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Counter to quickly extract top 5 keys\n",
    "# Can use a custom data structure (heap) for it if needed\n",
    "\n",
    "from collections import Counter\n",
    "keys_counter = Counter(keys_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 150000),\n",
       " ('record_date', 150000),\n",
       " ('name', 148062),\n",
       " ('dob', 143874),\n",
       " ('ssn', 142444)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Five most common keys\n",
    "keys_counter.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q3\n",
    "How many distinct first names appear in this data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two hierarchies for first name: name and name.firstname  \n",
    "Let's count both separately and then find the union."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using MongoDB's distinct() function\n",
    "distinct_firstnames = set(collection.distinct(\"name.firstname\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*collection.distinct(\"name\")* returns every unique entry in \"name\" field; that includes the nested {firstname, lastname} fields as well.  \n",
    "\n",
    "Iterating over those, we ignore them, and parse the other names by splitting at whitespace and considering the first word to be the first name, we make additions to above set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every distinct \"name\" in database\n",
    "for nm in collection.distinct(\"name\"):\n",
    "    # If that name is not a nested record\n",
    "    if type(nm) is not dict:\n",
    "        # Split the name at space and consider first word to be first name\n",
    "        fname, *lname = nm.split(\" \")\n",
    "        distinct_firstnames.add(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distinct_firstnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q4\n",
    "How many distinct street names appear in this data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to first names, we again have two fields which represent street name -  \n",
    "One is straightforward: *\"address.street\"*  \n",
    "and the other is *\"address\"* itself\n",
    "\n",
    "We need to extract the street name from the string address and maintain a set of unique ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_streets = set()\n",
    "\n",
    "# Ignore the digits at the start\n",
    "# After you encounter the first space, \n",
    "# try to find two groups of alphabets (lower/upper case), seperated by a space\n",
    "street_regex = r'(?:\\d+).*?\\s+([A-z]+\\s[A-z]+)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By modifying this regular expression, we can refine our criterion for \"street names\".  \n",
    "Right now, it captures two-worded street names that follow a block number. [(Reference)](https://en.wikipedia.org/wiki/Street_or_road_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# For every distinct \"address\"\n",
    "for addr in collection.distinct(\"address\"):    \n",
    "    # If the address is nested, just consider the \"street\"\n",
    "    if type(addr) is dict:\n",
    "        addr = addr.get(\"street\", \"\")\n",
    "    m = re.match(street_regex, addr)\n",
    "    if m:\n",
    "        distinct_streets.add(m.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79999"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distinct_streets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can implement a regex in MongoDB's find() function; but it will return you matching records, not individual fields  \n",
    "You have to run a regex again on the result, which is double work. Hence, the above approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72485"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.find({\n",
    "    \"address\": {\"$regex\": r'(?:\\d+).*?\\s+(.+)'}\n",
    "}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q5\n",
    "What are the 5 most common US area codes in the phone number field?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "area_codes = {}\n",
    "phone_regex = r'(?:\\+?)\\(?([1-9]\\d{2})\\)?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we take a similar approach as streets, by defining a 'regular expression' to extract the 3-digit area code from the phone number field.  \n",
    "We store it in a dictionary, which acts as a counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For every record in database\n",
    "for record in collection.find():\n",
    "    # If it has a \"phone\" field\n",
    "    phone = record.get(\"phone\", None)\n",
    "    if phone:\n",
    "        # Try to match it to the regex to extract area code\n",
    "        m = re.match(phone_regex, phone)\n",
    "        if m:\n",
    "            code = m.group(1)\n",
    "            # Increment the count for that area code\n",
    "            area_codes[code] = area_codes.get(code, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('913', 119), ('947', 117), ('488', 117), ('796', 114), ('270', 113)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(area_codes).most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems 'Kansas' is the most widely observed area code in our database, followed closely by 'Michigan' and the 'mysterious' 488."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean-up\n",
    "db.people.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers\n",
    "\n",
    "#### Q1: List of all of the nested named fields\n",
    "['address', 'address.city', 'address.state', 'address.street', 'address.zip', 'dob', 'email', 'id', 'name', 'name.firstname', 'name.lastname', 'name.middlename', 'phone', 'record_date', 'ssn']\n",
    "\n",
    "#### Q2a: What percentage of the records contain the field?\n",
    "| Field | Percentage |\n",
    "| :------- | -------: |\n",
    "|address          | 90.95% |\n",
    "|address.city     | 40.82% |\n",
    "|address.state    | 40.82% |\n",
    "|address.street   | 40.82% |\n",
    "|address.zip      | 40.82% |\n",
    "|dob              | 95.92% |\n",
    "|email            | 87.25% |\n",
    "|id              | 100.00% |\n",
    "|name             | 98.71% |\n",
    "|name.firstname   | 70.01% |\n",
    "|name.lastname    | 70.01% |\n",
    "|name.middlename  | 29.11% |\n",
    "|phone            | 93.51% |\n",
    "|record_date     | 100.00% |\n",
    "|ssn              | 94.96% |\n",
    "\n",
    "#### Q2b: What are the five most common values of the field?\n",
    "| Field | Frequency |\n",
    "| :---- | --------: |\n",
    "| 'id' | 150014 |\n",
    "| 'record_date' | 150014 |\n",
    "| 'name' | 148076 |\n",
    "| 'dob' | 143888 |\n",
    "| 'ssn' | 142458 |\n",
    " \n",
    "#### Q3: How many distinct first names appear in this data set?\n",
    "695\n",
    "\n",
    "#### Q4: How many distinct street names appear in this data set?\n",
    "79999\n",
    "\n",
    "#### Q5: What are the 5 most common US area codes in the phone number field?\n",
    "| Area Code | Frequency |\n",
    "| :-------: | :-------: |\n",
    "| (913) | 119 |\n",
    "| (947) | 117 |\n",
    "| (488) | 117 |\n",
    "| (796) | 114 |\n",
    "| (270) | 113 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclustion\n",
    "\n",
    "Overall, storing our records in a NoSQL (MongoDB) database, didn't help us much.  \n",
    "It made easy to access and query the database, thanks to PyMongo wrapper; but we didn't utilize the underlying efficiency of MongoDB.  \n",
    "It was considerably easy to load the JSONL formatted data into MongoDB.\n",
    "\n",
    "As for analysis, we mostly parsed all the records for each of our questions.  \n",
    "To achieve efficiency and avoid repeat querying for records, we can iterate over each record once (maybe even while loading it into database), and calculate the required statistics at that time.  \n",
    "But, with current situation, we were able to answer all of our queries very quickly.  \n",
    "Depending on what more are we supposed to do with the data, and based on the type and frequency of queries, we can modify the functions and use some Hadoop speedups or non-structured querying advantages."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
